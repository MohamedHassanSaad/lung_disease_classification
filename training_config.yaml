
training:
  input_size: [224, 224, 3]
  batch_size: [16, 32, 64]
  learning_rate:
    min: 1e-5
    max: 1e-2
    type: log_uniform
  optimizer: [SGD, Adam]
  epochs: 100
  early_stopping:
    monitor: val_auc
    patience: 10
  regularization:
    dropout_fc: [0.3, 0.6]
    dropout_conv: [0.0, 0.3]
    weight_decay:
      min: 1e-6
      max: 1e-3
      type: log_uniform

data:
  augmentation:
    rotation: [-15, 15]
    flip: [horizontal, vertical]
    zoom: [0.8, 1.2]
    contrast: CLAHE
  normalization: [0, 1]
  segmentation: U-Net
